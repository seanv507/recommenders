{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanv507/recommenders/blob/master/docs/examples/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dEaVsqSgNyQ"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4FyfuZX-gTKS"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT8AyHRMNh41"
      },
      "source": [
        "# TensorFlow Recommenders: Quickstart\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/quickstart\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f-reQ11gbLB"
      },
      "source": [
        "In this tutorial, we build a simple matrix factorization model using the [MovieLens 100K dataset](https://grouplens.org/datasets/movielens/100k/) with TFRS. We can use this model to recommend movies for a given user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA00wBE2Ntdm"
      },
      "source": [
        "### Import TFRS\n",
        "\n",
        "First, install and import TFRS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yzAaM85Z12D"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3oYt3R6Nr9l"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCxQ1CZcO2wh"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-mxBYjdO5m7"
      },
      "outputs": [],
      "source": [
        "# Ratings data.\n",
        "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
        "# Features of all the available movies.\n",
        "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
        "\n",
        "# Select the basic features.\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"]\n",
        "})\n",
        "movies = movies.map(lambda x: x[\"movie_title\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W0HSfmSNCWm"
      },
      "source": [
        "Build vocabularies to convert user ids and movie titles into integer indices for embedding layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I1VTEjHzpfX"
      },
      "outputs": [],
      "source": [
        "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
        "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
        "\n",
        "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
        "movie_titles_vocabulary.adapt(movies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrch6rVBOB9Q"
      },
      "source": [
        "### Define a model\n",
        "\n",
        "We can define a TFRS model by inheriting from `tfrs.Model` and implementing the `compute_loss` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5dNbDZwOIHR"
      },
      "outputs": [],
      "source": [
        "class MovieLensModel(tfrs.Model):\n",
        "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
        "  # these are still plain Keras Models.\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      user_model: tf.keras.Model,\n",
        "      movie_model: tf.keras.Model,\n",
        "      task: tfrs.tasks.Retrieval):\n",
        "    super().__init__()\n",
        "\n",
        "    # Set up user and movie representations.\n",
        "    self.user_model = user_model\n",
        "    self.movie_model = movie_model\n",
        "\n",
        "    # Set up a retrieval task.\n",
        "    self.task = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    # Define how the loss is computed.\n",
        "\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "\n",
        "    return self.task(user_embeddings, movie_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdwtgUCEOI8y"
      },
      "source": [
        "Define the two models and the retrieval task."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2022 The TensorFlow Recommenders Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# pylint: disable=g-import-not-at-top\n",
        "\"\"\"Layers for retrieving top K recommendations from factorized retrieval models.\"\"\"\n",
        "\n",
        "import abc\n",
        "import contextlib\n",
        "from typing import Dict, Optional, Text, Tuple, Union\n",
        "import uuid\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "  # ScaNN is an optional dependency, and might not be present.\n",
        "  from scann import scann_ops\n",
        "  _HAVE_SCANN = True\n",
        "except ImportError:\n",
        "  _HAVE_SCANN = False\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def _wrap_batch_too_small_error(k: int):\n",
        "  \"\"\"Context manager that provides a more helpful error message.\"\"\"\n",
        "\n",
        "  try:\n",
        "    yield\n",
        "  except tf.errors.InvalidArgumentError as e:\n",
        "    error_message = str(e)\n",
        "    if \"input must have at least k columns\" in error_message:\n",
        "      raise ValueError(\"Tried to retrieve k={k} top items, but the candidate \"\n",
        "                       \"dataset batch size is too small. This may be because \"\n",
        "                       \"your candidate batch size is too small or the last \"\n",
        "                       \"batch of your dataset is too small. \"\n",
        "                       \"To resolve this, increase your batch size, set the \"\n",
        "                       \"drop_remainder argument to True when batching your \"\n",
        "                       \"candidates, or set the handle_incomplete_batches \"\n",
        "                       \"argument to True in the constructor. \".format(k=k))\n",
        "    else:\n",
        "      raise\n",
        "\n",
        "\n",
        "def _take_along_axis(arr: tf.Tensor, indices: tf.Tensor) -> tf.Tensor:\n",
        "  \"\"\"Partial TF implementation of numpy.take_along_axis.\n",
        "\n",
        "  See\n",
        "  https://numpy.org/doc/stable/reference/generated/numpy.take_along_axis.html\n",
        "  for details.\n",
        "\n",
        "  Args:\n",
        "    arr: 2D matrix of source values.\n",
        "    indices: 2D matrix of indices.\n",
        "\n",
        "  Returns:\n",
        "    2D matrix of values selected from the input.\n",
        "  \"\"\"\n",
        "\n",
        "  row_indices = tf.tile(\n",
        "      tf.expand_dims(tf.range(tf.shape(indices)[0]), 1),\n",
        "      [1, tf.shape(indices)[1]])\n",
        "  gather_indices = tf.concat(\n",
        "      [tf.reshape(row_indices, (-1, 1)),\n",
        "       tf.reshape(indices, (-1, 1))], axis=1)\n",
        "\n",
        "  return tf.reshape(tf.gather_nd(arr, gather_indices), tf.shape(indices))\n",
        "\n",
        "\n",
        "def _exclude(scores: tf.Tensor, identifiers: tf.Tensor, exclude: tf.Tensor,\n",
        "             k: int) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "  \"\"\"Removes a subset of candidates from top K candidates.\n",
        "\n",
        "  For each row of inputs excludes those candidates whose identifiers match\n",
        "  any of the identifiers present in the exclude matrix for that row.\n",
        "\n",
        "  Args:\n",
        "    scores: 2D matrix of candidate scores.\n",
        "    identifiers: 2D matrix of candidate identifiers.\n",
        "    exclude: 2D matrix of identifiers to exclude.\n",
        "    k: Number of candidates to return.\n",
        "\n",
        "  Returns:\n",
        "    Tuple of (scores, indices) of candidates after exclusions.\n",
        "  \"\"\"\n",
        "\n",
        "  idents = tf.expand_dims(identifiers, -1)\n",
        "  exclude = tf.expand_dims(exclude, 1)\n",
        "\n",
        "  isin = tf.math.reduce_any(tf.math.equal(idents, exclude), -1)\n",
        "\n",
        "  # Set the scores of the excluded candidates to a very low value.\n",
        "  adjusted_scores = (scores - tf.cast(isin, tf.float32) * 1.0e5)\n",
        "\n",
        "  k = tf.math.minimum(k, tf.shape(scores)[1])\n",
        "\n",
        "  _, indices = tf.math.top_k(adjusted_scores, k=k)\n",
        "\n",
        "  return _take_along_axis(scores,\n",
        "                          indices), _take_along_axis(identifiers, indices)\n",
        "\n",
        "\n",
        "def _check_candidates_with_identifiers(candidates: tf.data.Dataset) -> None:\n",
        "  \"\"\"Checks preconditions the dataset used for indexing.\"\"\"\n",
        "\n",
        "  spec = candidates.element_spec\n",
        "\n",
        "  if isinstance(spec, tuple):\n",
        "    if len(spec) != 2:\n",
        "      raise ValueError(\n",
        "          \"The dataset must yield candidate embeddings or \"\n",
        "          \"tuples of (candidate identifiers, candidate embeddings). \"\n",
        "          f\"Got {spec} instead.\"\n",
        "      )\n",
        "\n",
        "    identifiers_spec, candidates_spec = spec\n",
        "\n",
        "    if candidates_spec.shape[0] != identifiers_spec.shape[0]:\n",
        "      raise ValueError(\n",
        "          \"Candidates and identifiers have to have the same batch dimension. \"\n",
        "          f\"Got {candidates_spec.shape[0]} and {identifiers_spec.shape[0]}.\"\n",
        "      )\n",
        "\n",
        "\n",
        "class TopK(tf.keras.Model, abc.ABC):\n",
        "  \"\"\"Interface for top K layers.\n",
        "\n",
        "  Implementers must provide the following two methods:\n",
        "\n",
        "  1. `index`: takes a tensor of candidate embeddings and creates the retrieval\n",
        "    index.\n",
        "  2. `call`: takes a tensor of queries and returns top K candidates for those\n",
        "    queries.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, k: int, **kwargs) -> None:\n",
        "    \"\"\"Initializes the base class.\"\"\"\n",
        "\n",
        "    super().__init__(**kwargs)\n",
        "    self._k = k\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def index(\n",
        "      self,\n",
        "      candidates: tf.Tensor,\n",
        "      identifiers: Optional[tf.Tensor] = None) -> \"TopK\":\n",
        "    \"\"\"Builds the retrieval index.\n",
        "\n",
        "    When called multiple times the existing index will be dropped and a new one\n",
        "    created.\n",
        "\n",
        "    Args:\n",
        "      candidates: Matrix of candidate embeddings.\n",
        "      identifiers: Optional tensor of candidate identifiers. If\n",
        "        given, these will be used as identifiers of top candidates returned\n",
        "        when performing searches. If not given, indices into the candidates\n",
        "        tensor will be returned instead.\n",
        "\n",
        "    Returns:\n",
        "      Self.\n",
        "    \"\"\"\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def index_from_dataset(\n",
        "      self,\n",
        "      candidates: tf.data.Dataset\n",
        "  ) -> \"TopK\":\n",
        "    \"\"\"Builds the retrieval index.\n",
        "\n",
        "    When called multiple times the existing index will be dropped and a new one\n",
        "    created.\n",
        "\n",
        "    Args:\n",
        "      candidates: Dataset of candidate embeddings or (candidate identifier,\n",
        "        candidate embedding) pairs. If the dataset returns tuples,\n",
        "        the identifiers will be used as identifiers of top candidates\n",
        "        returned when performing searches. If not given, indices into the\n",
        "        candidates dataset will be given instead.\n",
        "\n",
        "    Returns:\n",
        "      Self.\n",
        "\n",
        "    Raises:\n",
        "      ValueError if the dataset does not have the correct structure.\n",
        "    \"\"\"\n",
        "\n",
        "    _check_candidates_with_identifiers(candidates)\n",
        "\n",
        "    spec = candidates.element_spec\n",
        "\n",
        "    if isinstance(spec, tuple):\n",
        "      identifiers_and_candidates = list(candidates)\n",
        "      candidates = tf.concat(\n",
        "          [embeddings for _, embeddings in identifiers_and_candidates],\n",
        "          axis=0\n",
        "      )\n",
        "      identifiers = tf.concat(\n",
        "          [identifiers for identifiers, _ in identifiers_and_candidates],\n",
        "          axis=0\n",
        "      )\n",
        "    else:\n",
        "      candidates = tf.concat(list(candidates), axis=0)\n",
        "      identifiers = None\n",
        "\n",
        "    return self.index(candidates, identifiers)\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def call(\n",
        "      self,\n",
        "      queries: Union[tf.Tensor, Dict[Text, tf.Tensor]],\n",
        "      k: Optional[int] = None,\n",
        "  ) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"Query the index.\n",
        "\n",
        "    Args:\n",
        "      queries: Query features. If `query_model` was provided in the constructor,\n",
        "        these can be raw query features that will be processed by the query\n",
        "        model before performing retrieval. If `query_model` was not provided,\n",
        "        these should be pre-computed query embeddings.\n",
        "      k: The number of candidates to retrieve. If not supplied, defaults to the\n",
        "        `k` value supplied in the constructor.\n",
        "\n",
        "    Returns:\n",
        "      Tuple of (top candidate scores, top candidate identifiers).\n",
        "\n",
        "    Raises:\n",
        "      ValueError if `index` has not been called.\n",
        "    \"\"\"\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  @tf.function\n",
        "  def query_with_exclusions(\n",
        "      self,\n",
        "      queries: Union[tf.Tensor, Dict[Text, tf.Tensor]],\n",
        "      exclusions: tf.Tensor,\n",
        "      k: Optional[int] = None,\n",
        "  ) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"Query the index.\n",
        "\n",
        "    Args:\n",
        "      queries: Query features. If `query_model` was provided in the constructor,\n",
        "        these can be raw query features that will be processed by the query\n",
        "        model before performing retrieval. If `query_model` was not provided,\n",
        "        these should be pre-computed query embeddings.\n",
        "      exclusions: `[query_batch_size, num_to_exclude]` tensor of identifiers to\n",
        "        be excluded from the top-k calculation. This is most commonly used to\n",
        "        exclude previously seen candidates from retrieval. For example, if a\n",
        "        user has already seen items with ids \"42\" and \"43\", you could set\n",
        "        exclude to `[[\"42\", \"43\"]]`.\n",
        "      k: The number of candidates to retrieve. Defaults to constructor `k`\n",
        "        parameter if not supplied.\n",
        "\n",
        "    Returns:\n",
        "      Tuple of (top candidate scores, top candidate identifiers).\n",
        "\n",
        "    Raises:\n",
        "      ValueError if `index` has not been called.\n",
        "      ValueError if `queries` is not a tensor (after being passed through\n",
        "        the query model).\n",
        "    \"\"\"\n",
        "\n",
        "    # Ideally, `exclusions` would simply be an optional parameter to\n",
        "    # `call`. However, Keras is unable to handle `call` signatures\n",
        "    # that have more than one Tensor input parameter. The alternative\n",
        "    # is to either pack all inputs into the first positional argument\n",
        "    # (via tuples or dicts), or else have a separate method. We opt\n",
        "    # for the second solution here. The ergonomics in either case aren't\n",
        "    # great, but having two methods is simpler to explain.\n",
        "    # See https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/\n",
        "    # python/keras/engine/base_layer.py#L942 for details of why Keras\n",
        "    # puts us in this predicament.\n",
        "\n",
        "    k = k if k is not None else self._k\n",
        "\n",
        "    adjusted_k = k + exclusions.shape[1]\n",
        "    x, y = self(queries=queries, k=adjusted_k)\n",
        "    return _exclude(x, y, exclude=exclusions, k=k)\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def is_exact(self) -> bool:\n",
        "    \"\"\"Indicates whether the results returned by the layer are exact.\n",
        "\n",
        "    Some layers may return approximate scores: for example, the ScaNN layer\n",
        "    may return approximate results.\n",
        "\n",
        "    Returns:\n",
        "      True if the layer returns exact results, and False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def _reset_tf_function_cache(self):\n",
        "    \"\"\"Resets the tf.function cache.\n",
        "\n",
        "    We need to invalidate the compiled tf.function cache here. We just\n",
        "    dropped some variables and created new ones. The concrete function is\n",
        "    still referring to the old ones - and because it only holds weak\n",
        "    references, this does not prevent the old variables being garbage\n",
        "    collected. The end result is that it references dead objects.\n",
        "    To resolve this, we throw away the existing tf.function object and\n",
        "    create a new one.\n",
        "    \"\"\"\n",
        "\n",
        "    if hasattr(self.query_with_exclusions, \"python_function\"):\n",
        "      self.query_with_exclusions = tf.function(\n",
        "          self.query_with_exclusions.python_function)\n",
        "\n",
        "  def _compute_score(self, queries: tf.Tensor,\n",
        "                     candidates: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Computes the standard dot product score from queries and candidates.\n",
        "\n",
        "    Args:\n",
        "      queries: Tensor of queries for which the candidates are to be retrieved.\n",
        "      candidates: Tensor of candidate embeddings.\n",
        "\n",
        "    Returns:\n",
        "      The dot product of queries and candidates.\n",
        "    \"\"\"\n",
        "\n",
        "    return tf.matmul(queries, candidates, transpose_b=True)\n",
        "\n",
        "\n",
        "class Streaming(TopK):\n",
        "  \"\"\"Retrieves K highest scoring items and their ids from a large dataset.\n",
        "\n",
        "  Used to efficiently retrieve top K query-candidate scores from a dataset,\n",
        "  along with the top scoring candidates' identifiers.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               query_model: Optional[tf.keras.Model] = None,\n",
        "               k: int = 10,\n",
        "               handle_incomplete_batches: bool = True,\n",
        "               num_parallel_calls: int = tf.data.AUTOTUNE,\n",
        "               sorted_order: bool = True) -> None:\n",
        "    \"\"\"Initializes the layer.\n",
        "\n",
        "    Args:\n",
        "      query_model: Optional Keras model for representing queries. If provided,\n",
        "        will be used to transform raw features into query embeddings when\n",
        "        querying the layer. If not provided, the layer will expect to be given\n",
        "        query embeddings as inputs.\n",
        "      k: Number of top scores to retrieve.\n",
        "      handle_incomplete_batches: When True, candidate batches smaller than k\n",
        "        will be correctly handled at the price of some performance. As an\n",
        "        alternative, consider using the drop_remainer option when batching the\n",
        "        candidate dataset.\n",
        "      num_parallel_calls: Degree of parallelism when computing scores. Defaults\n",
        "        to autotuning.\n",
        "      sorted_order: If the resulting scores should be returned in sorted order.\n",
        "        setting this to False may result in a small increase in performance.\n",
        "\n",
        "    Raises:\n",
        "      ValueError if candidate elements are not tuples.\n",
        "    \"\"\"\n",
        "\n",
        "    super().__init__(k=k)\n",
        "\n",
        "    self.query_model = query_model\n",
        "    self._candidates = None\n",
        "    self._handle_incomplete_batches = handle_incomplete_batches\n",
        "    self._num_parallel_calls = num_parallel_calls\n",
        "    self._sorted = sorted_order\n",
        "\n",
        "    self._counter = self.add_weight(name=\"counter\", dtype=tf.int32, trainable=False)\n",
        "\n",
        "  def index_from_dataset(\n",
        "      self,\n",
        "      candidates: tf.data.Dataset\n",
        "  ) -> \"TopK\":\n",
        "\n",
        "    _check_candidates_with_identifiers(candidates)\n",
        "\n",
        "    self._candidates = candidates\n",
        "\n",
        "    return self\n",
        "\n",
        "  def index(  # pytype: disable=signature-mismatch  # overriding-parameter-type-checks\n",
        "      self,\n",
        "      candidates: tf.data.Dataset,\n",
        "      identifiers: Optional[tf.data.Dataset] = None) -> \"Streaming\":\n",
        "    \"\"\"Not implemented. Please call `index_from_dataset` instead.\"\"\"\n",
        "\n",
        "    raise NotImplementedError(\n",
        "        \"The streaming top k class only accepts datasets. \"\n",
        "        \"Please call `index_from_dataset` instead.\"\n",
        "    )\n",
        "\n",
        "  def call(\n",
        "      self,\n",
        "      queries: Union[tf.Tensor, Dict[Text, tf.Tensor]],\n",
        "      k: Optional[int] = None,\n",
        "  ) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "\n",
        "    k = k if k is not None else self._k\n",
        "\n",
        "    if self._candidates is None:\n",
        "      raise ValueError(\"The `index` method must be called first to \"\n",
        "                       \"create the retrieval index.\")\n",
        "\n",
        "    if self.query_model is not None:\n",
        "      queries = self.query_model(queries)\n",
        "\n",
        "    # Reset the element counter.\n",
        "    self._counter.assign(0)\n",
        "\n",
        "    def top_scores(candidate_index: tf.Tensor,\n",
        "                   candidate_batch: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "      \"\"\"Computes top scores and indices for a batch of candidates.\"\"\"\n",
        "\n",
        "      scores = self._compute_score(queries, candidate_batch)\n",
        "\n",
        "      if self._handle_incomplete_batches:\n",
        "        k_ = tf.math.minimum(k, tf.shape(scores)[1])\n",
        "      else:\n",
        "        k_ = k\n",
        "\n",
        "      scores, indices = tf.math.top_k(scores, k=k_, sorted=self._sorted)\n",
        "\n",
        "      return scores, tf.gather(candidate_index, indices)\n",
        "\n",
        "    def top_k(state: Tuple[tf.Tensor, tf.Tensor],\n",
        "              x: Tuple[tf.Tensor, tf.Tensor]) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "      \"\"\"Reduction function.\n",
        "\n",
        "      Returns top K scores from a combination of existing top K scores and new\n",
        "      candidate scores, as well as their corresponding indices.\n",
        "\n",
        "      Args:\n",
        "        state: tuple of [query_batch_size, k] tensor of highest scores so far\n",
        "          and [query_batch_size, k] tensor of indices of highest scoring\n",
        "          elements.\n",
        "        x: tuple of [query_batch_size, k] tensor of new scores and\n",
        "          [query_batch_size, k] tensor of new indices.\n",
        "\n",
        "      Returns:\n",
        "        Tuple of [query_batch_size, k] tensors of highest scores and indices\n",
        "          from state and x.\n",
        "      \"\"\"\n",
        "      state_scores, state_indices = state\n",
        "      x_scores, x_indices = x\n",
        "\n",
        "      joined_scores = tf.concat([state_scores, x_scores], axis=1)\n",
        "      joined_indices = tf.concat([state_indices, x_indices], axis=1)\n",
        "\n",
        "      if self._handle_incomplete_batches:\n",
        "        k_ = tf.math.minimum(k, tf.shape(joined_scores)[1])\n",
        "      else:\n",
        "        k_ = k\n",
        "\n",
        "      scores, indices = tf.math.top_k(joined_scores, k=k_, sorted=self._sorted)\n",
        "\n",
        "      return scores, tf.gather(joined_indices, indices, batch_dims=1)\n",
        "\n",
        "    def enumerate_rows(batch: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "      \"\"\"Enumerates rows in each batch using a total element counter.\"\"\"\n",
        "\n",
        "      starting_counter = self._counter.read_value()\n",
        "      end_counter = self._counter.assign_add(tf.shape(batch)[0])\n",
        "\n",
        "      return tf.range(starting_counter, end_counter), batch\n",
        "\n",
        "    if not isinstance(self._candidates.element_spec, tuple):\n",
        "      # We don't have identifiers.\n",
        "      candidates = self._candidates.map(enumerate_rows)\n",
        "      index_dtype = tf.int32\n",
        "    else:\n",
        "      candidates = self._candidates\n",
        "      index_dtype = self._candidates.element_spec[0].dtype\n",
        "\n",
        "    # Initialize the state with dummy scores and candidate indices.\n",
        "    initial_state = (tf.zeros((tf.shape(queries)[0], 0), dtype=tf.float32),\n",
        "                     tf.zeros((tf.shape(queries)[0], 0), dtype=index_dtype))\n",
        "\n",
        "    with _wrap_batch_too_small_error(k):\n",
        "      results = (\n",
        "          candidates\n",
        "          # Compute scores over all candidates, and select top k in each batch.\n",
        "          # Each element is a ([query_batch_size, k] tensor,\n",
        "          # [query_batch_size, k] tensor) of scores and indices (where query_\n",
        "          # batch_size is the leading dimension of the input query embeddings).\n",
        "          .map(top_scores, num_parallel_calls=self._num_parallel_calls)\n",
        "          # Reduce into a single tuple of output tensors by keeping a running\n",
        "          # tally of top k scores and indices.\n",
        "          .reduce(initial_state, top_k))\n",
        "\n",
        "    return results\n",
        "\n",
        "  def is_exact(self) -> bool:\n",
        "    return True\n",
        "\n",
        "\n",
        "class BruteForce(TopK):\n",
        "  \"\"\"Brute force retrieval.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               query_model: Optional[tf.keras.Model] = None,\n",
        "               k: int = 10,\n",
        "               name: Optional[Text] = None):\n",
        "    \"\"\"Initializes the layer.\n",
        "\n",
        "    Args:\n",
        "      query_model: Optional Keras model for representing queries. If provided,\n",
        "        will be used to transform raw features into query embeddings when\n",
        "        querying the layer. If not provided, the layer will expect to be given\n",
        "        query embeddings as inputs.\n",
        "      k: Default k.\n",
        "      name: Name of the layer.\n",
        "    \"\"\"\n",
        "\n",
        "    super().__init__(k=k, name=name)\n",
        "\n",
        "    self.query_model = query_model\n",
        "    self._candidates = None\n",
        "\n",
        "  def index(\n",
        "      self,\n",
        "      candidates: tf.Tensor,\n",
        "      identifiers: Optional[tf.Tensor] = None\n",
        "  ) -> \"BruteForce\":\n",
        "\n",
        "    if identifiers is None:\n",
        "      identifiers = tf.range(candidates.shape[0])\n",
        "\n",
        "    if tf.rank(candidates) != 2:\n",
        "      raise ValueError(\n",
        "          f\"The candidates tensor must be 2D (got {candidates.shape}).\")\n",
        "\n",
        "    if candidates.shape[0] != identifiers.shape[0]:\n",
        "      raise ValueError(\n",
        "          \"The candidates and identifiers tensors must have the same number of rows \"\n",
        "          f\"(got {candidates.shape[0]} candidates rows and {identifiers.shape[0]} \"\n",
        "          \"identifier rows). \"\n",
        "      )\n",
        "\n",
        "    # We need any value that has the correct dtype.\n",
        "    identifiers_initial_value = tf.zeros((), dtype=identifiers.dtype)\n",
        "\n",
        "    self._identifiers = self.add_weight(\n",
        "        name=\"identifiers\",\n",
        "        dtype=identifiers.dtype,\n",
        "        shape=identifiers.shape,\n",
        "        initializer=tf.keras.initializers.Constant(\n",
        "            value=identifiers_initial_value),\n",
        "        trainable=False)\n",
        "    self._candidates = self.add_weight(\n",
        "        name=\"candidates\",\n",
        "        dtype=candidates.dtype,\n",
        "        shape=candidates.shape,\n",
        "        initializer=tf.keras.initializers.Zeros(),\n",
        "        trainable=False)\n",
        "\n",
        "    self._identifiers.assign(identifiers)\n",
        "    self._candidates.assign(candidates)\n",
        "\n",
        "    self._reset_tf_function_cache()\n",
        "\n",
        "    return self\n",
        "\n",
        "  def call(\n",
        "      self,\n",
        "      queries: Union[tf.Tensor, Dict[Text, tf.Tensor]],\n",
        "      k: Optional[int] = None,\n",
        "  ) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "\n",
        "    k = k if k is not None else self._k\n",
        "\n",
        "    if self._candidates is None:\n",
        "      raise ValueError(\"The `index` method must be called first to \"\n",
        "                       \"create the retrieval index.\")\n",
        "\n",
        "    if self.query_model is not None:\n",
        "      queries = self.query_model(queries)\n",
        "\n",
        "    scores = self._compute_score(queries, self._candidates)\n",
        "\n",
        "    values, indices = tf.math.top_k(scores, k=k)\n",
        "\n",
        "    return values, tf.gather(self._identifiers, indices)\n",
        "\n",
        "  def is_exact(self) -> bool:\n",
        "    return True\n",
        "\n",
        "\n",
        "class ScaNN(TopK):\n",
        "  \"\"\"ScaNN approximate retrieval index for a factorized retrieval model.\n",
        "\n",
        "  This layer uses the state-of-the-art\n",
        "  [ScaNN](https://github.com/google-research/google-research/tree/master/scann)\n",
        "  library to retrieve the best candidates for a given query.\n",
        "\n",
        "  To understand how to use this layer effectively, have a look at the efficient\n",
        "  retrieval\n",
        "  [tutorial](https://www.tensorflow.org/recommenders/examples/efficient_serving).\n",
        "\n",
        "  To deploy this layer in TensorFlow Serving you can use our customized\n",
        "  TensorFlow Serving Docker container, available on\n",
        "  [Docker Hub](https://hub.docker.com/r/google/tf-serving-scann). You can also\n",
        "  build the image yourself from the\n",
        "  [Dockerfile](https://github.com/google-research/google-research/tree/master/scann/tf_serving).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               query_model: Optional[tf.keras.Model] = None,\n",
        "               k: int = 10,\n",
        "               distance_measure: Text = \"dot_product\",\n",
        "               num_leaves: int = 100,\n",
        "               num_leaves_to_search: int = 10,\n",
        "               training_iterations: int = 12,\n",
        "               dimensions_per_block: int = 2,\n",
        "               num_reordering_candidates: Optional[int] = None,\n",
        "               parallelize_batch_searches: bool = True,\n",
        "               name: Optional[Text] = None):\n",
        "    \"\"\"Initializes the layer.\n",
        "\n",
        "    Args:\n",
        "      query_model: Optional Keras model for representing queries. If provided,\n",
        "        will be used to transform raw features into query embeddings when\n",
        "        querying the layer. If not provided, the layer will expect to be given\n",
        "        query embeddings as inputs.\n",
        "      k: Default number of results to retrieve. Can be overridden in `call`.\n",
        "      distance_measure: Distance metric to use.\n",
        "      num_leaves: Number of leaves.\n",
        "      num_leaves_to_search: Number of leaves to search.\n",
        "      training_iterations: Number of training iterations when performing tree\n",
        "        building.\n",
        "      dimensions_per_block: Controls the dataset compression ratio. A higher\n",
        "        number results in greater compression, leading to faster scoring but\n",
        "        less accuracy and more memory usage.\n",
        "      num_reordering_candidates: If set, the index will perform a final\n",
        "        refinement pass on `num_reordering_candidates` candidates after\n",
        "        retrieving an initial set of neighbours. This helps improve accuracy,\n",
        "        but requires the original representations to be kept, and so will\n",
        "        increase the final model size.\"\n",
        "      parallelize_batch_searches: Whether batch querying should be done in\n",
        "        parallel.\n",
        "      name: Name of the layer.\n",
        "\n",
        "    Raises:\n",
        "      ImportError: if the scann library is not installed.\n",
        "    \"\"\"\n",
        "\n",
        "    super().__init__(k=k, name=name)\n",
        "\n",
        "    if not _HAVE_SCANN:\n",
        "      raise ImportError(\n",
        "          \"The scann library is not present. Please install it using \"\n",
        "          \"`pip install scann` to use the ScaNN layer.\")\n",
        "\n",
        "    self.query_model = query_model\n",
        "    self._k = k\n",
        "    self._parallelize_batch_searches = parallelize_batch_searches\n",
        "    self._num_reordering_candidates = num_reordering_candidates\n",
        "    self._training_iterations = training_iterations\n",
        "    self._identifiers = None\n",
        "\n",
        "    def build_searcher(candidates):\n",
        "      builder = scann_ops.builder(\n",
        "          db=candidates,\n",
        "          num_neighbors=self._k,\n",
        "          distance_measure=distance_measure)\n",
        "\n",
        "      builder = builder.tree(\n",
        "          num_leaves=num_leaves,\n",
        "          num_leaves_to_search=num_leaves_to_search,\n",
        "          training_iterations=self._training_iterations,\n",
        "      )\n",
        "      builder = builder.score_ah(dimensions_per_block=dimensions_per_block)\n",
        "\n",
        "      if self._num_reordering_candidates is not None:\n",
        "        builder = builder.reorder(self._num_reordering_candidates)\n",
        "\n",
        "      # Set a unique name to prevent unintentional sharing between\n",
        "      # ScaNN instances.\n",
        "      return builder.build(shared_name=f\"{self.name}/{uuid.uuid4()}\")\n",
        "\n",
        "    self._build_searcher = build_searcher\n",
        "    self._serialized_searcher = None\n",
        "\n",
        "  def index(\n",
        "      self,\n",
        "      candidates: tf.Tensor,\n",
        "      identifiers: Optional[tf.Tensor] = None) -> \"ScaNN\":\n",
        "\n",
        "    if len(candidates.shape) != 2:\n",
        "      raise ValueError(\n",
        "          f\"The candidates tensor must be 2D (got {candidates.shape}).\")\n",
        "\n",
        "    if identifiers is not None and candidates.shape[0] != identifiers.shape[0]:\n",
        "      raise ValueError(\n",
        "          \"The candidates and identifiers tensors must have the same number of rows \"\n",
        "          f\"(got {candidates.shape[0]} candidates rows and {identifiers.shape[0]} \"\n",
        "          \"identifier rows). \"\n",
        "      )\n",
        "\n",
        "    self._serialized_searcher = self._build_searcher(\n",
        "        candidates).serialize_to_module()\n",
        "\n",
        "    if identifiers is not None:\n",
        "      # We need any value that has the correct dtype.\n",
        "      identifiers_initial_value = tf.zeros((), dtype=identifiers.dtype)\n",
        "      self._identifiers = self.add_weight(\n",
        "          name=\"identifiers\",\n",
        "          dtype=identifiers.dtype,\n",
        "          shape=identifiers.shape,\n",
        "          initializer=tf.keras.initializers.Constant(\n",
        "              value=identifiers_initial_value),\n",
        "          trainable=False)\n",
        "      self._identifiers.assign(identifiers)\n",
        "\n",
        "    self._reset_tf_function_cache()\n",
        "\n",
        "    return self\n",
        "\n",
        "  def call(self,\n",
        "           queries: Union[tf.Tensor, Dict[Text, tf.Tensor]],\n",
        "           k: Optional[int] = None) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "\n",
        "    k = k if k is not None else self._k\n",
        "\n",
        "    if self._serialized_searcher is None:\n",
        "      raise ValueError(\"The `index` method must be called first to \"\n",
        "                       \"create the retrieval index.\")\n",
        "\n",
        "    searcher = scann_ops.searcher_from_module(self._serialized_searcher)\n",
        "\n",
        "    if self.query_model is not None:\n",
        "      queries = self.query_model(queries)\n",
        "\n",
        "    if not isinstance(queries, tf.Tensor):\n",
        "      raise ValueError(f\"Queries must be a tensor, got {type(queries)}.\")\n",
        "\n",
        "    if len(queries.shape) == 2:\n",
        "      if self._parallelize_batch_searches:\n",
        "        result = searcher.search_batched_parallel(\n",
        "            queries, final_num_neighbors=k)\n",
        "      else:\n",
        "        result = searcher.search_batched(queries, final_num_neighbors=k)\n",
        "      indices = result.indices\n",
        "      distances = result.distances\n",
        "    elif len(queries.shape) == 1:\n",
        "      result = searcher.search(queries, final_num_neighbors=k)\n",
        "      indices = result.index\n",
        "      distances = result.distance\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          f\"Queries must be of rank 2 or 1, got {len(queries.shape)}.\")\n",
        "\n",
        "    if self._identifiers is None:\n",
        "      return distances, indices\n",
        "\n",
        "    return distances, tf.gather(self._identifiers, indices)\n",
        "\n",
        "  def is_exact(self) -> bool:\n",
        "    return False"
      ],
      "metadata": {
        "id": "neW4-d-ynuzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvtnUN6aUY4U"
      },
      "outputs": [],
      "source": [
        "# Define user and movie models.\n",
        "user_model = tf.keras.Sequential([\n",
        "    user_ids_vocabulary,\n",
        "    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), 64)\n",
        "])\n",
        "movie_model = tf.keras.Sequential([\n",
        "    movie_titles_vocabulary,\n",
        "    tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), 64)\n",
        "])\n",
        "\n",
        "# Define your objectives.\n",
        "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
        "    movies.batch(128).map(movie_model)\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMV0HpzmJGWk"
      },
      "source": [
        "\n",
        "### Fit and evaluate it.\n",
        "\n",
        "Create the model, train it, and generate predictions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2tQDhqkOKf1"
      },
      "outputs": [],
      "source": [
        "# Create a retrieval model.\n",
        "model = MovieLensModel(user_model, movie_model, task)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
        "\n",
        "# Train for 3 epochs.\n",
        "model.fit(ratings.batch(4096), epochs=3)\n",
        "\n",
        "# Use brute-force search to set up retrieval using the trained representations.\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "index.index_from_dataset(\n",
        "    movies.batch(100).map(lambda title: (title, model.movie_model(title))))\n",
        "\n",
        "# Get some recommendations.\n",
        "_, titles = index(np.array([\"42\"]))\n",
        "print(f\"Top 3 recommendations for user 42: {titles[0, :3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neJAJVwbReNd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "quickstart.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}